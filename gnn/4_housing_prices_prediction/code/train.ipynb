{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston housing price predictino on Boston housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该数据集有22行的前言, 且没有逗号分割, 且14列数据每一行被分割为两行. 导入前需要对应进行预处理."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston housing dataset\n",
    "response = requests.get('http://lib.stat.cmu.edu/datasets/boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.00632', '18.00', '2.310', '0', '0.5380', '6.5750', '65.20', '4.0900', '1', '296.0', '15.30', '396.90', '4.98', '24.00'], ['0.02731', '0.00', '7.070', '0', '0.4690', '6.4210', '78.90', '4.9671', '2', '242.0', '17.80', '396.90', '9.14', '21.60']] ...\n",
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  MEDV  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "data=response.text\n",
    "\n",
    "# Remove the meta-information at the beginning\n",
    "data=data.split('\\n')[22:]\n",
    "\n",
    "# The data rows are splited over two lines. Join them together\n",
    "joined_data = []\n",
    "for i in range(0,len(data)-1,2):\n",
    "    row=data[i].split()+data[i+1].split()\n",
    "    joined_data.append(row)\n",
    "\n",
    "print(joined_data[:2],'...')\n",
    "# convert to numpy array\n",
    "data=np.array(joined_data).astype(float)\n",
    "\n",
    "# convert the data to a DataFrame\n",
    "columns=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "df=pd.DataFrame(data,columns=columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "X=df.drop('MEDV',axis=1).values\n",
    "y=df['MEDV'].values\n",
    "\n",
    "# standardize the features\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "# split data into training and testing dataset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pytorch tensors\n",
    "X_train=torch.FloatTensor(X_train)\n",
    "y_train=torch.FloatTensor(y_train).view(-1,1)\n",
    "X_test=torch.FloatTensor(X_test)\n",
    "y_test=torch.FloatTensor(y_test).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston housing model\n",
    "class BostonHousingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BostonHousingModel,self).__init__()\n",
    "        self.layer1=nn.Linear(13,64)\n",
    "        self.layer2=nn.Linear(64,64)\n",
    "        self.layer3=nn.Linear(64,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.layer1(x))\n",
    "        x=torch.relu(self.layer2(x))\n",
    "        x=self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model, define loss function and optimizer\n",
    "model=BostonHousingModel()\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 439.78094482421875\n",
      "Epoch 100, Loss: 65.26469421386719\n",
      "Epoch 150, Loss: 26.282752990722656\n",
      "Epoch 200, Loss: 19.871841430664062\n",
      "Epoch 250, Loss: 16.445039749145508\n",
      "Epoch 300, Loss: 14.146811485290527\n",
      "Epoch 350, Loss: 12.584306716918945\n",
      "Epoch 400, Loss: 11.533455848693848\n",
      "Epoch 450, Loss: 10.719816207885742\n",
      "Epoch 500, Loss: 10.033358573913574\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "for epoch in range(500):\n",
    "    # forward pass\n",
    "    outputs=model(X_train)\n",
    "    loss=criterion(outputs,y_train)\n",
    "    \n",
    "    # backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(epoch+1)%50==0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  13.90117359161377\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred=model(X_test)\n",
    "    \n",
    "print('Test loss: ', criterion(y_pred, y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dropout, learning rate scheduling, and early stopping to optimize the\n",
    "# model\n",
    "class OptiBostonHousingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptiBostonHousingModel,self).__init__()\n",
    "        self.layer1=nn.Linear(13,128)\n",
    "        self.layer2=nn.Linear(128,64)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.layer3=nn.Linear(64,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.layer1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=torch.relu(self.layer2(x))\n",
    "        x=self.dropout(x)\n",
    "        x=self.layer3(x)\n",
    "        return x\n",
    "        \n",
    "opti_model=OptiBostonHousingModel()\n",
    "critetion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "# reduce learning rate every 100 steps\n",
    "scheduler=StepLR(optimizer,step_size=100,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store losses of training and validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
