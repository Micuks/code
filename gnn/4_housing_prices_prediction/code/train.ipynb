{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston housing price predictino on Boston housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该数据集有22行的前言, 且没有逗号分割, 且14列数据每一行被分割为两行. 导入前需要对应进行预处理."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston housing dataset\n",
    "response = requests.get('http://lib.stat.cmu.edu/datasets/boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.00632', '18.00', '2.310', '0', '0.5380', '6.5750', '65.20', '4.0900', '1', '296.0', '15.30', '396.90', '4.98', '24.00'], ['0.02731', '0.00', '7.070', '0', '0.4690', '6.4210', '78.90', '4.9671', '2', '242.0', '17.80', '396.90', '9.14', '21.60']] ...\n",
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  MEDV  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "data=response.text\n",
    "\n",
    "# Remove the meta-information at the beginning\n",
    "data=data.split('\\n')[22:]\n",
    "\n",
    "# The data rows are splited over two lines. Join them together\n",
    "joined_data = []\n",
    "for i in range(0,len(data)-1,2):\n",
    "    row=data[i].split()+data[i+1].split()\n",
    "    joined_data.append(row)\n",
    "\n",
    "print(joined_data[:2],'...')\n",
    "# convert to numpy array\n",
    "data=np.array(joined_data).astype(float)\n",
    "\n",
    "# convert the data to a DataFrame\n",
    "columns=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "df=pd.DataFrame(data,columns=columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "X=df.drop('MEDV',axis=1).values\n",
    "y=df['MEDV'].values\n",
    "\n",
    "# standardize the features\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "# split data into training and testing dataset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pytorch tensors\n",
    "X_train=torch.FloatTensor(X_train)\n",
    "y_train=torch.FloatTensor(y_train).view(-1,1)\n",
    "X_test=torch.FloatTensor(X_test)\n",
    "y_test=torch.FloatTensor(y_test).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston housing model\n",
    "class BostonHousingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BostonHousingModel,self).__init__()\n",
    "        self.layer1=nn.Linear(13,64)\n",
    "        self.layer2=nn.Linear(64,64)\n",
    "        self.layer3=nn.Linear(64,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.layer1(x))\n",
    "        x=torch.relu(self.layer2(x))\n",
    "        x=self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model, define loss function and optimizer\n",
    "model=BostonHousingModel()\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 381.8599548339844\n",
      "Epoch 100, Loss: 57.943546295166016\n",
      "Epoch 150, Loss: 25.20885467529297\n",
      "Epoch 200, Loss: 19.815107345581055\n",
      "Epoch 250, Loss: 16.540985107421875\n",
      "Epoch 300, Loss: 14.289535522460938\n",
      "Epoch 350, Loss: 12.771340370178223\n",
      "Epoch 400, Loss: 11.739974975585938\n",
      "Epoch 450, Loss: 10.954638481140137\n",
      "Epoch 500, Loss: 10.293461799621582\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "for epoch in range(500):\n",
    "    # forward pass\n",
    "    outputs=model(X_train)\n",
    "    loss=criterion(outputs,y_train)\n",
    "    \n",
    "    # backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(epoch+1)%50==0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "torch.save(model.state_dict(), 'best_model_old.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  12.326370239257812\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred=model(X_test)\n",
    "    \n",
    "print('Test loss: ', criterion(y_pred, y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dropout, learning rate scheduling, and early stopping to optimize the\n",
    "# model\n",
    "class OptiBostonHousingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptiBostonHousingModel,self).__init__()\n",
    "        self.layer1=nn.Linear(13,128)\n",
    "        self.layer2=nn.Linear(128,64)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.layer3=nn.Linear(64,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.layer1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=torch.relu(self.layer2(x))\n",
    "        x=self.dropout(x)\n",
    "        x=self.layer3(x)\n",
    "        return x\n",
    "        \n",
    "model=OptiBostonHousingModel()\n",
    "critetion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.09)\n",
    "# reduce learning rate every 100 steps\n",
    "scheduler=StepLR(optimizer,step_size=100,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store losses of training and validation\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "# split validation from training\n",
    "val_ratio = 0.1\n",
    "val_len = int(len(X_train) * val_ratio)\n",
    "train_len = len(X_train) - val_len\n",
    "X_train, X_val = torch.utils.data.random_split(X_train, [train_len, val_len])\n",
    "y_train, y_val = torch.utils.data.random_split(y_train, [train_len, val_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.dataset\n",
    "X_val=X_val.dataset\n",
    "y_train=y_train.dataset\n",
    "y_val=y_val.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 27.11713981628418, Validation Loss: 7.157723903656006\n",
      "Epoch 100, Train Loss: 32.16069412231445, Validation Loss: 7.157723903656006\n",
      "Epoch 150, Train Loss: 31.317283630371094, Validation Loss: 7.157723903656006\n",
      "Epoch 200, Train Loss: 31.56045913696289, Validation Loss: 7.157723903656006\n",
      "Epoch 250, Train Loss: 28.05300521850586, Validation Loss: 7.157723903656006\n",
      "Epoch 300, Train Loss: 33.324302673339844, Validation Loss: 7.157723903656006\n",
      "Epoch 350, Train Loss: 28.748680114746094, Validation Loss: 7.157723903656006\n",
      "Epoch 400, Train Loss: 27.83043098449707, Validation Loss: 7.157723903656006\n",
      "Epoch 450, Train Loss: 33.288204193115234, Validation Loss: 7.157723903656006\n",
      "Epoch 500, Train Loss: 28.712465286254883, Validation Loss: 7.157723903656006\n",
      "Test Loss:  12.081153869628906\n"
     ]
    }
   ],
   "source": [
    "# Training new model\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_preds = model(X_train)\n",
    "    train_loss = criterion(train_preds, y_train)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_preds = model(X_val)\n",
    "        valid_loss = criterion(valid_preds, y_val)\n",
    "\n",
    "    train_losses.append(train_loss.item())\n",
    "    valid_losses.append(valid_loss.item())\n",
    "\n",
    "    if valid_loss.item() < best_valid_loss:\n",
    "        best_valid_loss = valid_loss.item()\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}, Train Loss: {train_loss.item()}, Validation Loss: {valid_loss.item()}\"\n",
    "        )\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred=model(X_test)\n",
    "    \n",
    "print(\"Test Loss: \", criterion(y_pred, y_test).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型比较\n",
    "对于回归问题(Regression problem), 使用平均平方差(Mean Squared Error, MSE)作为\n",
    "Loss, 并使用此来比较两个模型的拟合水平. 可以看到两个模型的Loss相差不大. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss of the old model: 12.326370239257812\n",
      "Test Loss of the new model: 12.081153869628906\n"
     ]
    }
   ],
   "source": [
    "model_old=BostonHousingModel()\n",
    "model_old.load_state_dict(torch.load('best_model_old.pt'))\n",
    "\n",
    "model_new=OptiBostonHousingModel()\n",
    "model_new.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "model_old.eval()\n",
    "model_new.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_old=model_old(X_test)\n",
    "    y_pred_new=model_new(X_test)\n",
    "    \n",
    "print(f'Test Loss of the old model: {criterion(y_pred_old, y_test).item()}')\n",
    "print(f'Test Loss of the new model: {criterion(y_pred_new, y_test).item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
